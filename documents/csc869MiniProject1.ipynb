{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Note: this function alters the column of variableName of the original data set \n",
    "   Function takes as input a data frame, the name of the continous variable (String), number of bins (int)\n",
    "\"\"\"\n",
    "def descretizer(data, variableName, binNum):\n",
    "\n",
    "    d = data[variableName].to_numpy().reshape(len(data),1) #convert data frame to array \n",
    "    kbins = KBinsDiscretizer(n_bins=binNum, encode='ordinal', strategy='uniform') #apply kbinsDiscretizer\n",
    "    data_trans = kbins.fit_transform(d) #apply kbinsDiscretizer to array\n",
    "    data[variableName] = pd.DataFrame(data_trans) #convert array back to data frame and replace column in original data\n",
    "\n",
    "    return #nothing to return since the original data column has been transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function takes as input an n by k data frame and response variable (String) and returns a list of n by 2 data frames\"\"\"\n",
    "def makeDataFrames(data, response):\n",
    "    dataFrameList = [] #initialize empty list of data frames \n",
    "    for i in range(len(data.columns)-1): #exclude the response column (this assumes response column is the last column)\n",
    "        columnName = data.columns[i]\n",
    "        d = {response: data[response], columnName: data[columnName]}\n",
    "        #print(pd.DataFrame(d))\n",
    "        dataFrameList += [pd.DataFrame(d)] #make n by 2 data frame\n",
    "\n",
    "    return dataFrameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function takes as input a list of n by 2 data frames with a categorical variable of m categories and returns a list of 2 by m dataframes of conditional probabilities\"\"\"\n",
    "\n",
    "def makeConditionalProb(dataFramelist):\n",
    "        \n",
    "    conditionalProbList = [] #initialize empty list of conditional probability arrays\n",
    "    \n",
    "    for k in range(len(dataFramelist)): #for each predictor\n",
    "        df = dataFramelist[k] #get n by 2 data frame at index k \n",
    "        columnName = df.columns[1] #get the name of the associated predictor variable \n",
    "        m = len(df[columnName].unique()) #number of predictor categories\n",
    "        a = np.empty((2, m)) #initialize empty array of conditional probabilities. 2 is number of rows (high/low income). m is number of columns (number of predictor categories)\n",
    "        for i in range(2):\n",
    "            for j in range(m):\n",
    "                category = df[columnName].unique()[j]\n",
    "                x = len(df[(df.income == i) & (df[columnName] == category)]) + 1 #(for each predictor) count the total number of income i for category j \n",
    "                \n",
    "                #(+ 1 prevents getting probabilities of 0)\n",
    "\n",
    "                a[i][j] = x/(countIncome[i] + 1)\n",
    "\n",
    "        #make array more reader-friendly\n",
    "        a = pd.DataFrame(a)\n",
    "        a.index = ['low income', 'high income'] #add row names\n",
    "        a.columns = df[columnName].unique()  #add column names\n",
    "\n",
    "        conditionalProbList += [a]  #add array to list of conditional probability arrays\n",
    "\n",
    "    return conditionalProbList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function takes in as input test data (data frame), training data (data frame), and the response label (String). Function outputs a new data set with the predicted response values \n",
    "\"\"\"\n",
    "import copy \n",
    "\n",
    "def classifier(test_data, train_data, response):\n",
    "   \n",
    "    dataFrameList =  makeDataFrames(train_data, response)  #pre-process train_data into a list of n by 2 data frames\n",
    "    \n",
    "    conditionalProb = makeConditionalProb(dataFrameList) #store the list of conditional probability arrays\n",
    "  \n",
    "    predicted_data = copy.copy(test_data) #make a copy of the test_data because it will be altered \n",
    "\n",
    "\n",
    "    for i in range(len(test_data)): #for each row in test data...\n",
    "\n",
    "        prob_low = probLowIncome #initialize prob of low income with prior\n",
    "        prob_high = probHighIncome #initialize prob of high income with prior\n",
    "        \n",
    "        for j in range(len(test_data.loc[i][:-1])): #for each predictor in row i (len of row should always be 14); (the last value, income, is removed)\n",
    "\n",
    "            variableName = test_data.loc[i][:-1][j] \n",
    "\n",
    "            #check if variableName is in train_data set \n",
    "            if (train_data.iloc[:, j] == variableName).any():\n",
    "\n",
    "                prob_low *= conditionalProb[j][variableName][0] #multiply the conditional probability of low income given variable j \n",
    "                prob_high *= conditionalProb[j][variableName][1] #multiply the conditional probability of high income given variable j \n",
    "\n",
    "            else:  #if variableName is not in the train_data set, then make prob_low income/high income equal to 1 for that variableName\n",
    "                prob_low *= 1\n",
    "                prob_high *= 1\n",
    "\n",
    "\n",
    "        if prob_high > prob_low:\n",
    "            prediction = 1   \n",
    "        else:\n",
    "            prediction = 0\n",
    "\n",
    "        #replace the class label with prediction \n",
    "        predicted_data.iat[i, -1] = prediction\n",
    "            \n",
    "    return predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function inputs number of k folds (int) and a data set (dataframe). The function outputs the average performance score of k crossvalidation data sets. NOTE function is very slow, but it works\n",
    "\"\"\"\n",
    "import copy\n",
    "\n",
    "def kFold(k, data):\n",
    "    cross_val_data = copy.copy(data) #make a copy of data \n",
    "    cross_val_data = cross_val_data.sample(frac = 1, random_state = 869).reset_index(drop = True) #randomly shuffle data \n",
    "    x = int(len(data)/k) #length of each cross validation set \n",
    "    y = {} #initialize dictionary to store the cross validation data sets\n",
    "\n",
    "    for i in range(k):\n",
    "        y[i] = cross_val_data.iloc[:x, :].reset_index(drop = True) #get the first x rows of the shuffled data\n",
    "        cross_val_data = cross_val_data.iloc[x:, :] #update data set without the first x rows \n",
    "\n",
    "    ############################ calculate performance of cross validation #############################################\n",
    "\n",
    "    F1_scores = []\n",
    "    #accuracy_scores = []\n",
    "\n",
    "\n",
    "    for i in range(k):       #for each k fold...\n",
    "\n",
    "        train_data, test_data = kFoldHelper(i, y) #get train data and test data \n",
    "\n",
    "        F1_scores += [performance(train_data, test_data, \"income\")[0]] #get the F_1 results \n",
    "        #accuracy_scores += [performance(train_data, test_data, \"income\")[1]] #get the accuracy results \n",
    "\n",
    "    F1 = sum(F1_scores)/k #calculate the average F1 score\n",
    "    #accuracy = sum(accuracy_scores)/k #calculate the average accuracy score \n",
    "\n",
    "    return F1 #, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this function inputs a number and a dictionary of data sets. Function outputs a training data frame and a testing data frame whose dictionary key corresponds with j \n",
    "\"\"\"\n",
    "def kFoldHelper(j, my_dict):\n",
    "    l = []\n",
    "    for i in range(len(my_dict)): \n",
    "        if i != j: #get all validation sets except the one for testing \n",
    "            l += [my_dict[i]] #compile training data \n",
    "\n",
    "    train_data = pd.concat(l, ignore_index=True) #concat training data \n",
    "    test_data = my_dict[j].reset_index(drop = True)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function takes as input test_data (data frames). Function implements Naive Bayes classification to predict the response variable. Outputs accuracy, precision, recall, F-1 measure, and a confusion matrix\n",
    "\"\"\"\n",
    "def performance(test_data, train_data, response):\n",
    "    #get predicted data \n",
    "    predicted_data = classifier(test_data, train_data, response)\n",
    "\n",
    "    #initialize confusion matrix values\n",
    "    t_positive = 0\n",
    "    f_positive = 0\n",
    "    t_negative = 0\n",
    "    f_negative = 0\n",
    "\n",
    "    for i in range(len(test_data)): #for each row in test data\n",
    "\n",
    "        test_label = test_data.loc[i][-1] #get actual values of the response variable\n",
    "        \n",
    "        predicted_label = predicted_data.loc[i][-1] #get predicted values of the response variable \n",
    "\n",
    "        if test_label == 1 and predicted_label == 1:\n",
    "            t_positive += 1\n",
    "       \n",
    "        elif test_label == 0 and predicted_label == 1:\n",
    "            f_positive += 1\n",
    "\n",
    "        elif test_label == 0 and predicted_label == 0:\n",
    "            t_negative += 1\n",
    "\n",
    "        else:\n",
    "            f_negative += 1\n",
    "    \n",
    "    accuracy = (t_positive + t_negative)/(t_positive + t_negative + f_positive + f_negative)\n",
    "    precision = t_positive/(t_positive + f_positive +0.00001)\n",
    "    recall = t_positive/(t_positive + f_negative +0.00001) \n",
    "    F_1 = 2*precision*recall/(precision + recall +0.00001)\n",
    "\n",
    "    confusionMatrix = {\"C1\": [t_positive, f_positive], \"C2\": [f_negative, t_negative]}\n",
    "    confusionMatrix = pd.DataFrame(confusionMatrix, index = [\"C1\", \"C2\"])\n",
    "\n",
    "    #print('false pos: ', f_positive)\n",
    "    #print('false neg: ', f_negative)\n",
    "    #print('true neg: ', t_negative)\n",
    "    #print('true pos: ', t_positive)\n",
    "    #print('accuracy: ', accuracy)\n",
    "    #print('precision: ', precision)\n",
    "    #print('F_1: ', F_1)\n",
    "\n",
    "\n",
    "    return F_1, accuracy, confusionMatrix #, accuracy , precision, recall, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
